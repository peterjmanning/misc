{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ffcd8af-ff5c-449a-9c1b-9fbb3cdf548c",
   "metadata": {},
   "source": [
    "***\n",
    "# .IPYNB Similarity Scorer\n",
    "***\n",
    "## Motivation:\n",
    "We can use the following program to determine similarity between two texts, programs, or mixture of the two. This can be useful in systematically looking for similarity between programs and texts due to the critical role that language plays in shaping market decisions, regulatory compliance, and financial communications. We can also use this to easily identify plagiarism and gain financial insight, if texts are highly similar, it could be a sign of reuse and stagantion, if texts vary heavily, it could be a sign of diversification of strategy, etc.\n",
    "## Model Explanation:\n",
    "Implemented are two functions that respectively convert ipynb files to text only, and imported sentence transformer encoders encode the text. Similarity is measured as cosine similarity between each text. Finally, a score tensor is outputted, which we directly access using the .item() method of a tensor object, grabbing this scalar value.\n",
    "## NECESSARY:\n",
    "### This function will only work if you are indexed into the folder containing the files you want to compare pairwise. you can use os.chdir(\"path\") where path is the path to the folder in order to change your directory to the folder containing the files for comparison.\n",
    "## \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "173f6b0f-1779-40e8-a014-9c94539a372d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import os\n",
    "import pandas as pd\n",
    "import itertools\n",
    "!pip install sentence-transformers\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "### ENSURE CURRENT WORKING DIRECTORY IS THE FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a9f8fc3-fa8c-4f6a-a1f2-7ef1604ed7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/memes/folder1\n",
      "['decoder.ipynb', 'survival.ipynb', 'Kevin_Berookhim_Homework3.ipynb', '191.ipynb', '.ipynb_checkpoints', 'Extra Credit - Exercise of NUMPY (Duration Analysis).ipynb']\n"
     ]
    }
   ],
   "source": [
    "#folderName = \"folder1\"\n",
    "#os.chdir(folderName)\n",
    "print(os.getcwd()) #folderName= ## make sure you index into the folder you wish to inspect\n",
    "print(os.listdir()) #this should print the files you wish to compare\n",
    "files = os.listdir()\n",
    "pairNames = list(itertools.combinations(files,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76acb918-0a46-49d3-bfb8-3b990174cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import hugging Face model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "\n",
    "#extract only the text for each file in files:\n",
    "def extract(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        notebook = json.load(f)\n",
    "    # Combine text from markdown and code cells\n",
    "    content = []\n",
    "    for cell in notebook.get('cells', []):\n",
    "        if cell.get('cell_type') in ['markdown', 'code']:\n",
    "            content.append(' '.join(cell.get('source', [])))\n",
    "    return ' '.join(content)\n",
    "\n",
    "#compute cosine similarity\n",
    "def similarity(text1, text2):\n",
    "    embedding1 = model.encode(text1, convert_to_tensor=True)\n",
    "    embedding2 = model.encode(text2, convert_to_tensor=True)\n",
    "    similarityScore = util.cos_sim(embedding1, embedding2)\n",
    "    return str(similarityScore.item() * 100)[0:5] + \"%\" #round the decimal and convert to percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2792fa7-bde0-4c4c-b019-fae203477e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity score: 96.80%\n"
     ]
    }
   ],
   "source": [
    "#TEST THAT THE MODEL WORKS:\n",
    "x = \"hello my friend, too, is a big boy\"\n",
    "y = \"hello my friend too is a big boy\"\n",
    "\n",
    "g = similarity(x,y)\n",
    "print(f\"similarity score: {g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc75b2d8-0207-4694-a205-301436fd91ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [extract(file) for file in files if file != \".ipynb_checkpoints\"]\n",
    "pairsList = list(itertools.combinations(texts, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4094aeb1-0979-45f2-b7bd-089a4fc45b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "simDict = {}\n",
    "name = 0\n",
    "for pair in pairsList:\n",
    "    x = similarity(pair[0], pair[1])\n",
    "    simDict[pairNames[name]] = x\n",
    "    name+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89909b55-6779-4c89-ac43-67e7730269cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text One</th>\n",
       "      <th>Text Two</th>\n",
       "      <th>Similarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decoder.ipynb</td>\n",
       "      <td>survival.ipynb</td>\n",
       "      <td>11.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decoder.ipynb</td>\n",
       "      <td>Kevin_Berookhim_Homework3.ipynb</td>\n",
       "      <td>5.911%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decoder.ipynb</td>\n",
       "      <td>191.ipynb</td>\n",
       "      <td>26.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>decoder.ipynb</td>\n",
       "      <td>.ipynb_checkpoints</td>\n",
       "      <td>19.96%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>decoder.ipynb</td>\n",
       "      <td>Extra Credit - Exercise of NUMPY (Duration Ana...</td>\n",
       "      <td>16.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>survival.ipynb</td>\n",
       "      <td>Kevin_Berookhim_Homework3.ipynb</td>\n",
       "      <td>26.27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>survival.ipynb</td>\n",
       "      <td>191.ipynb</td>\n",
       "      <td>24.05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>survival.ipynb</td>\n",
       "      <td>.ipynb_checkpoints</td>\n",
       "      <td>32.90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>survival.ipynb</td>\n",
       "      <td>Extra Credit - Exercise of NUMPY (Duration Ana...</td>\n",
       "      <td>37.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kevin_Berookhim_Homework3.ipynb</td>\n",
       "      <td>191.ipynb</td>\n",
       "      <td>29.16%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Text One  \\\n",
       "0                    decoder.ipynb   \n",
       "1                    decoder.ipynb   \n",
       "2                    decoder.ipynb   \n",
       "3                    decoder.ipynb   \n",
       "4                    decoder.ipynb   \n",
       "5                   survival.ipynb   \n",
       "6                   survival.ipynb   \n",
       "7                   survival.ipynb   \n",
       "8                   survival.ipynb   \n",
       "9  Kevin_Berookhim_Homework3.ipynb   \n",
       "\n",
       "                                            Text Two Similarity Score  \n",
       "0                                     survival.ipynb           11.18%  \n",
       "1                    Kevin_Berookhim_Homework3.ipynb           5.911%  \n",
       "2                                          191.ipynb           26.59%  \n",
       "3                                 .ipynb_checkpoints           19.96%  \n",
       "4  Extra Credit - Exercise of NUMPY (Duration Ana...           16.42%  \n",
       "5                    Kevin_Berookhim_Homework3.ipynb           26.27%  \n",
       "6                                          191.ipynb           24.05%  \n",
       "7                                 .ipynb_checkpoints           32.90%  \n",
       "8  Extra Credit - Exercise of NUMPY (Duration Ana...           37.08%  \n",
       "9                                          191.ipynb           29.16%  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    [(key[0], key[1], value) for key, value in simDict.items()],\n",
    "    columns=['Text One', 'Text Two', 'Similarity Score']\n",
    ")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
